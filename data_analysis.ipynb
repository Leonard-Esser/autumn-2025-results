{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1ea57e",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d900bd",
   "metadata": {},
   "source": [
    "## Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c06747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6681c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670505f7",
   "metadata": {},
   "source": [
    "### Data access functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def data(root: Path) -> Path:\n",
    "    return root / \"data\"\n",
    "\n",
    "\n",
    "def output(root: Path) -> Path:\n",
    "    return data(root) / \"output\"\n",
    "\n",
    "\n",
    "def raw_results(root: Path) -> Path:\n",
    "    return data(root) / \"raw_results\" / \"raw_results.csv\"\n",
    "\n",
    "\n",
    "def subjects(root: Path) -> Path:\n",
    "    return data(root) / \"raw_results\" / \"subjects.csv\"\n",
    "\n",
    "\n",
    "def commits(root: Path) -> Path:\n",
    "    return data(root) / \"raw_results\" / \"commits.csv\"\n",
    "\n",
    "\n",
    "def truth(root: Path) -> Path:\n",
    "    return data(root) / \"truth\" / \"truth.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c2470",
   "metadata": {},
   "source": [
    "### Function to summarize DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable, Sequence\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "MetricFn = Callable[[pd.DataFrame], object]\n",
    "\n",
    "\n",
    "def _require_cols(g: pd.DataFrame, cols: Sequence[str]) -> None:\n",
    "    missing = [c for c in cols if c not in g.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Metrics\n",
    "# ---------------------------------------------------------------------\n",
    "def m_n_subjects(g: pd.DataFrame) -> int:\n",
    "    return int(len(g))\n",
    "\n",
    "\n",
    "def m_n_repos(g: pd.DataFrame) -> int:\n",
    "    _require_cols(g, [\"full_name_of_repo\"])\n",
    "    return int(g[\"full_name_of_repo\"].nunique())\n",
    "\n",
    "\n",
    "def m_n_commits(g: pd.DataFrame) -> int:\n",
    "    _require_cols(g, [\"commit_sha\"])\n",
    "    return int(g[\"commit_sha\"].nunique())\n",
    "\n",
    "\n",
    "def m_n_distinct_paths(g: pd.DataFrame) -> int:\n",
    "    _require_cols(g, [\"path\"])\n",
    "    return int(g[\"path\"].nunique())\n",
    "\n",
    "\n",
    "def m_positive_rate(g: pd.DataFrame) -> float:\n",
    "    _require_cols(g, [\"is_ccdc_event\"])\n",
    "    n = len(g)\n",
    "    return np.nan if n == 0 else float(g[\"is_ccdc_event\"].sum() / n)\n",
    "\n",
    "\n",
    "def m_n_distinct_channels(g: pd.DataFrame) -> int:\n",
    "    _require_cols(g, [\"detected_channels\"])\n",
    "    return int(\n",
    "        g[\"detected_channels\"]\n",
    "        .explode()\n",
    "        .dropna()\n",
    "        .nunique()\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Registry: metric_name -> (fn, required_columns)\n",
    "# ---------------------------------------------------------------------\n",
    "METRICS: dict[str, tuple[MetricFn, tuple[str, ...]]] = {\n",
    "    \"n_subjects\": (m_n_subjects, ()),\n",
    "    \"n_repos\": (m_n_repos, (\"full_name_of_repo\",)),\n",
    "    \"n_commits\": (m_n_commits, (\"commit_sha\",)),\n",
    "    \"n_distinct_paths\": (m_n_distinct_paths, (\"path\",)),\n",
    "    \"positive_rate\": (m_positive_rate, (\"is_ccdc_event\",)),\n",
    "    \"n_distinct_channels\": (\n",
    "        m_n_distinct_channels,\n",
    "        (\"detected_channels\",),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------\n",
    "@dataclass(frozen=True)\n",
    "class SummarizeConfig:\n",
    "    include_metrics: tuple[str, ...]\n",
    "    group_keys: tuple[str, ...] = ()\n",
    "    forbid_access_to_group_keys: bool = True\n",
    "    drop_group_keys_from_frame: bool = True\n",
    "    deny_columns: tuple[str, ...] = ()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Core summarization\n",
    "# ---------------------------------------------------------------------\n",
    "def summarize_subjects_configurable(\n",
    "    g: pd.DataFrame,\n",
    "    cfg: SummarizeConfig,\n",
    ") -> pd.Series:\n",
    "\n",
    "    g_eff = (\n",
    "        g.drop(columns=list(cfg.group_keys), errors=\"ignore\")\n",
    "        if cfg.drop_group_keys_from_frame and cfg.group_keys\n",
    "        else g\n",
    "    )\n",
    "\n",
    "    forbidden = set(cfg.deny_columns)\n",
    "    if cfg.forbid_access_to_group_keys:\n",
    "        forbidden |= set(cfg.group_keys)\n",
    "\n",
    "    out: dict[str, object] = {}\n",
    "\n",
    "    for name in cfg.include_metrics:\n",
    "        if name not in METRICS:\n",
    "            raise KeyError(\n",
    "                f\"Unknown metric: {name}. \"\n",
    "                f\"Known: {sorted(METRICS)}\"\n",
    "            )\n",
    "\n",
    "        fn, required = METRICS[name]\n",
    "\n",
    "        illegal = [c for c in required if c in forbidden]\n",
    "        if illegal:\n",
    "            raise ValueError(\n",
    "                f\"Metric '{name}' requires forbidden columns {illegal}. \"\n",
    "                f\"Forbidden: {sorted(forbidden)}\"\n",
    "            )\n",
    "\n",
    "        out[name] = fn(g_eff)\n",
    "\n",
    "    return pd.Series(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5a7b8",
   "metadata": {},
   "source": [
    "### Tupel with each and every available metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab99203",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_METRICS = (\n",
    "    \"n_subjects\",\n",
    "    \"n_repos\",\n",
    "    \"n_commits\",\n",
    "    \"n_distinct_paths\",\n",
    "    \"positive_rate\",\n",
    "    \"n_distinct_channels\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56f072",
   "metadata": {},
   "source": [
    "### Function to cast columns of DataFrame to Int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "def col_to_int(df: pd.DataFrame, int_cols: Iterable[str]) -> pd.DataFrame:\n",
    "    cols = [c for c in int_cols if c in df.columns]\n",
    "    df[cols] = df[cols].astype(\"Int64\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f1092",
   "metadata": {},
   "source": [
    "#### \"Popular\" Int64 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8846ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT_COLS_OF_SUMMARY = [\n",
    "    \"n_subjects\",\n",
    "    \"n_repos\",\n",
    "    \"n_commits\",\n",
    "    \"n_distinct_paths\",\n",
    "    \"n_distinct_channels\",\n",
    "]\n",
    "\n",
    "INT_COLS_OF_VC_STATS = [\n",
    "    \"n_categories\",\n",
    "    \"total_count\",\n",
    "    \"min_count\",\n",
    "    \"max_count\",\n",
    "    \"median_count\",\n",
    "    \"q1_count\",\n",
    "    \"q3_count\",\n",
    "    \"iqr_count\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea623c9d",
   "metadata": {},
   "source": [
    "### Boxplot stats function\n",
    "\n",
    "**Includes the mean average.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_stats(s: pd.Series) -> pd.Series:\n",
    "    s = s.dropna()\n",
    "\n",
    "    q1 = s.quantile(0.25)\n",
    "    q2 = s.quantile(0.50)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    lower_whisker = s[s >= q1 - 1.5 * iqr].min()\n",
    "    upper_whisker = s[s <= q3 + 1.5 * iqr].max()\n",
    "\n",
    "    n_outliers = ((s < lower_whisker) | (s > upper_whisker)).sum()\n",
    "\n",
    "    mean = s.mean()\n",
    "\n",
    "    return pd.Series({\n",
    "        \"q1\": q1,\n",
    "        \"median\": q2,\n",
    "        \"mean\": mean,\n",
    "        \"q3\": q3,\n",
    "        \"iqr\": iqr,\n",
    "        \"lower_whisker\": lower_whisker,\n",
    "        \"upper_whisker\": upper_whisker,\n",
    "        \"n_outliers\": n_outliers,\n",
    "        \"min\": s.min(),\n",
    "        \"max\": s.max(),\n",
    "        \"n\": len(s),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad3841",
   "metadata": {},
   "source": [
    "### Function to get descriptive statistics / stats for a given value_counts() result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_stats(vc: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Descriptive statistics for a value_counts() result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vc : pd.Series\n",
    "        Output of value_counts(): index = category, values = counts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Descriptive statistics of the distribution of counts\n",
    "    \"\"\"\n",
    "    vc = vc.dropna()\n",
    "\n",
    "    if vc.empty:\n",
    "        return pd.Series(dtype=\"float64\")\n",
    "\n",
    "    counts = vc.values\n",
    "\n",
    "    total = counts.sum()\n",
    "    n_categories = len(vc)\n",
    "\n",
    "    q1 = vc.quantile(0.25)\n",
    "    q2 = vc.quantile(0.50)\n",
    "    q3 = vc.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    top_1 = vc.iloc[0]\n",
    "    top_5_sum = vc.iloc[:5].sum() if n_categories >= 5 else total\n",
    "    top_10_sum = vc.iloc[:10].sum() if n_categories >= 10 else total\n",
    "\n",
    "    return pd.Series({\n",
    "        # structure\n",
    "        \"n_categories\": n_categories,\n",
    "        \"total_count\": total,\n",
    "\n",
    "        # distribution of counts\n",
    "        \"min_count\": vc.min(),\n",
    "        \"max_count\": vc.max(),\n",
    "        \"mean_count\": vc.mean(),\n",
    "        \"median_count\": q2,\n",
    "        \"q1_count\": q1,\n",
    "        \"q3_count\": q3,\n",
    "        \"iqr_count\": iqr,\n",
    "\n",
    "        # concentration / dominance\n",
    "        \"top_1_count\": top_1,\n",
    "        \"top_1_share\": top_1 / total,\n",
    "        \"top_5_share\": top_5_sum / total,\n",
    "        \"top_10_share\": top_10_sum / total,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd6245",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed9a43",
   "metadata": {},
   "source": [
    "### Reading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd58c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    raw_results(Path.cwd()),\n",
    "    low_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fae44",
   "metadata": {},
   "source": [
    "### Working with a copy of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14439eb",
   "metadata": {},
   "source": [
    "### Droping unnecessary columns / Keeping interesting ones\n",
    "\n",
    "I have decided not to analyse the snapshot data of a repo. Why not? Because it is snapshot data for the point in time when I gathered the data. If a repo \"has GitHub discussions\", I have no idea since when that is the case. What if I draw conclusions when actually GitHub discussions has been introduced for that repo just the day before pulling the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792aa719",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_OF_INTEREST = [\n",
    "    \"full_name_of_repo\",\n",
    "    \"commit_sha\",\n",
    "    \"path\",\n",
    "    \"is_ccdc_event\",\n",
    "    \"detected_channel\",\n",
    "    \"created_at\",\n",
    "    \"pushed_at\",\n",
    "    \"updated_at\",\n",
    "    \"date\",\n",
    "]\n",
    "\n",
    "UNNECESSARY_COLS = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if col not in COLS_OF_INTEREST:\n",
    "        UNNECESSARY_COLS.append(col)\n",
    "\n",
    "data.drop(columns=UNNECESSARY_COLS, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db651a",
   "metadata": {},
   "source": [
    "### Data conversion – if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bool(series: pd.Series) -> pd.Series:\n",
    "    if series.dtype == bool:\n",
    "        return series\n",
    "    s = series.astype(\"string\").str.strip().str.lower()\n",
    "    mapping = {\"true\": True, \"false\": False}\n",
    "    return s.map(mapping)\n",
    "\n",
    "\n",
    "data[\"is_ccdc_event\"] = to_bool(data[\"is_ccdc_event\"])\n",
    "\n",
    "data[\"detected_channel\"] = data[\"detected_channel\"].astype(\"string\").fillna(\"\")\n",
    "\n",
    "DATETIME_COLS = [\"created_at\", \"pushed_at\", \"updated_at\", \"date\"]\n",
    "\n",
    "for col in DATETIME_COLS:\n",
    "    if col in data.columns:\n",
    "        data[col] = pd.to_datetime(data[col], errors=\"coerce\", utc=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdabc97",
   "metadata": {},
   "source": [
    "### Channel aggregation – Introducing the subjects dataframe\n",
    "\n",
    "Objective: One row = one subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6231a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_COLS = [\n",
    "    \"full_name_of_repo\",\n",
    "    \"commit_sha\",\n",
    "    \"path\",\n",
    "]\n",
    "\n",
    "gb = data.groupby(KEY_COLS, dropna=False)\n",
    "\n",
    "\n",
    "def agg_channels(x: pd.Series) -> tuple[str, ...]:\n",
    "    vals = [\n",
    "        v\n",
    "        for v in x.astype(\"string\").tolist()\n",
    "        if isinstance(v, str) and v.strip() != \"\"\n",
    "    ]\n",
    "    return tuple(sorted(set(vals)))\n",
    "\n",
    "\n",
    "agg = gb.agg(\n",
    "    is_ccdc_event=(\"is_ccdc_event\", \"first\"),\n",
    "    detected_channels=(\"detected_channel\", agg_channels),\n",
    ")\n",
    "\n",
    "for col in COLS_OF_INTEREST:\n",
    "    if col not in KEY_COLS and col not in agg.columns and col != \"detected_channel\":\n",
    "        agg[col] = gb[col].first()\n",
    "\n",
    "subjects = agg.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985eb3c",
   "metadata": {},
   "source": [
    "### Adding \"first_activity\" column\n",
    "\n",
    "The first activity is the timestamp that is earlier: the commit or when the repo was officially created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb364b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects[\"first_activity\"] = (\n",
    "    subjects[[\"date\", \"created_at\"]]\n",
    "        .min(axis=1)\n",
    "        .groupby(subjects[\"full_name_of_repo\"], dropna=False)\n",
    "        .transform(\"min\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774cf701",
   "metadata": {},
   "source": [
    "### Adding \"repo_age\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee14f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects[\"repo_age\"] = (\n",
    "    (subjects[\"date\"] - subjects[\"first_activity\"]).to_numpy()\n",
    "    / np.timedelta64(1, \"D\")\n",
    ")\n",
    "\n",
    "subjects.sort_values([\"full_name_of_repo\", \"repo_age\"], inplace=True)\n",
    "subjects.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d40905",
   "metadata": {},
   "source": [
    "### Adding \"repo_age_group\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c26d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_GROUPS = [\n",
    "    (0, 1, \"0-1\"),\n",
    "    (1, 2, \"1-2\"),\n",
    "    (2, 3, \"2-3\"),\n",
    "    (3, 4, \"3-4\"),\n",
    "    (4, 5, \"4-5\"),\n",
    "    (5, 6, \"5-6\"),\n",
    "    (6, 7, \"6-7\"),\n",
    "    (7, 8, \"7-8\"),\n",
    "    (8, 9, \"8-9\"),\n",
    "    (9, 10, \"9-10\"),\n",
    "    (10, 11, \"10-11\"),\n",
    "    (11, 12, \"11-12\"),\n",
    "    (12, 13, \"12-13\"),\n",
    "    (13, 14, \"13-14\"),\n",
    "    (14, 15, \"14-15\"),\n",
    "    (15, 999, \"15+\"),\n",
    "]\n",
    "\n",
    "\n",
    "def assign_age_group(age_in_days: float) -> int | None:\n",
    "    if pd.isna(age_in_days):\n",
    "        return None\n",
    "    for lo, hi, label in AGE_GROUPS:\n",
    "        if lo * 365.25 <= age_in_days < hi * 365.25:\n",
    "            return lo\n",
    "    return None\n",
    "\n",
    "\n",
    "subjects[\"repo_age_group\"] = subjects[\"repo_age\"].apply(assign_age_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db442f0",
   "metadata": {},
   "source": [
    "### Adding \"year\" column for temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f895873",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects[\"year\"] = subjects[\"date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63721681",
   "metadata": {},
   "source": [
    "### Extracting a dedicated repos dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5557953",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = (\n",
    "    subjects\n",
    "        .groupby(\"full_name_of_repo\", as_index=False)\n",
    "        .agg(\n",
    "            created_at=(\"created_at\", \"first\"),\n",
    "            pushed_at=(\"pushed_at\", \"first\"),\n",
    "            updated_at=(\"updated_at\", \"first\"),\n",
    "            first_activity=(\"first_activity\", \"first\"),\n",
    "        )\n",
    ")\n",
    "\n",
    "subjects.drop(\n",
    "    columns=[\"created_at\", \"pushed_at\", \"updated_at\", \"first_activity\"],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c41692",
   "metadata": {},
   "source": [
    "### Adding \"last_activity\" and \"age_today\" columns to repos dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acad508",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos[\"last_activity\"] = repos[[\"pushed_at\", \"updated_at\"]].max(axis=1)\n",
    "\n",
    "repos[\"age_today\"] = repos[\"last_activity\"] - repos[\"first_activity\"]\n",
    "\n",
    "repos.sort_values(\"age_today\", ascending=False, inplace=True)\n",
    "repos.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ada82",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa7a4f",
   "metadata": {},
   "source": [
    "### How many of this and that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ae734",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = []\n",
    "cfg = SummarizeConfig(\n",
    "    include_metrics=ALL_METRICS,\n",
    "    group_keys=tuple(group_keys),\n",
    ")\n",
    "\n",
    "summary = summarize_subjects_configurable(subjects, cfg).to_frame().T\n",
    "\n",
    "summary = col_to_int(summary, INT_COLS_OF_SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579cae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332a6e2",
   "metadata": {},
   "source": [
    "### Earliest commit and latest commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_commit = subjects[\"date\"].idxmin()\n",
    "earliest_commit_repo = subjects.loc[earliest_commit, \"full_name_of_repo\"]\n",
    "earliest_commit_sha = subjects.loc[earliest_commit, \"commit_sha\"]\n",
    "print(f\"Earliest commit? {earliest_commit_sha}@{earliest_commit_repo} at {subjects[\"date\"].min()}\")\n",
    "latest_commit = subjects[\"repo_age\"].idxmax()\n",
    "latest_commit_repo = subjects.loc[latest_commit, \"full_name_of_repo\"]\n",
    "latest_commit_sha = subjects.loc[latest_commit, \"commit_sha\"]\n",
    "print(f\"Latest commit? {latest_commit_sha}@{latest_commit_repo} at {subjects[\"date\"].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5cab2a",
   "metadata": {},
   "source": [
    "### Subjects grouped by repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43537afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = [\"full_name_of_repo\"]\n",
    "\n",
    "cfg = SummarizeConfig(\n",
    "    include_metrics=(\n",
    "        \"n_subjects\",\n",
    "        \"n_commits\",\n",
    "        \"n_distinct_paths\",\n",
    "        \"positive_rate\",\n",
    "        \"n_distinct_channels\",\n",
    "    ),\n",
    "    group_keys=tuple(group_keys),\n",
    ")\n",
    "\n",
    "repo_summaries = (\n",
    "    subjects\n",
    "        .set_index(\"full_name_of_repo\")\n",
    "        .groupby(group_keys, dropna=True)\n",
    "        .apply(lambda g: summarize_subjects_configurable(g, cfg))\n",
    ")\n",
    "\n",
    "repo_summaries = col_to_int(repo_summaries, INT_COLS_OF_SUMMARY)\n",
    "repo_summaries.sort_values(\"n_subjects\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f5c51",
   "metadata": {},
   "source": [
    "### Subjects grouped by path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = [\"path\"]\n",
    "\n",
    "cfg = SummarizeConfig(\n",
    "    include_metrics=(\n",
    "        \"n_subjects\",\n",
    "        \"n_repos\",\n",
    "        \"n_commits\",\n",
    "        \"positive_rate\",\n",
    "        \"n_distinct_channels\",\n",
    "    ),\n",
    "    group_keys=tuple(group_keys),\n",
    ")\n",
    "\n",
    "path_summaries = (\n",
    "    subjects\n",
    "        .set_index(\"path\")\n",
    "        .groupby(group_keys, dropna=True)\n",
    "        .apply(lambda g: summarize_subjects_configurable(g, cfg))\n",
    ")\n",
    "\n",
    "path_summaries = col_to_int(path_summaries, INT_COLS_OF_SUMMARY)\n",
    "path_summaries.sort_values(\"n_subjects\", ascending=False, inplace=True)\n",
    "\n",
    "path_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bace5",
   "metadata": {},
   "source": [
    "### Detected channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe33bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_counts = (\n",
    "    subjects[\"detected_channels\"]\n",
    "        .explode()\n",
    "        .dropna()\n",
    "        .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d700b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats = value_counts_stats(channel_counts).to_frame().T\n",
    "channel_stats = col_to_int(channel_stats, INT_COLS_OF_VC_STATS)\n",
    "\n",
    "channel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Most frequently detected channel? {channel_counts.idxmax()} with {channel_counts.max()} counts\")\n",
    "print(f\"Least commonly recognized channel? {channel_counts.idxmin()} with {channel_counts.min()} counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f5e49",
   "metadata": {},
   "source": [
    "### Age (in days) of the repo at the time of the commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_age_stats = boxplot_stats(subjects[\"repo_age\"])\n",
    "print(repo_age_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360af24b",
   "metadata": {},
   "source": [
    "### Age group of the repo at the time of the commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca8697",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_age_group_stats = boxplot_stats(subjects[\"repo_age_group\"])\n",
    "print(repo_age_group_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40f4cc",
   "metadata": {},
   "source": [
    "### Year in which the commit took place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8765148",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_stats = boxplot_stats(subjects[\"year\"])\n",
    "print(year_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5753c",
   "metadata": {},
   "source": [
    "## Temporal Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7ea82",
   "metadata": {},
   "source": [
    "### Yearly summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a37f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = [\"year\"]\n",
    "\n",
    "cfg = SummarizeConfig(\n",
    "    include_metrics=ALL_METRICS,\n",
    "    group_keys=tuple(group_keys),\n",
    ")\n",
    "\n",
    "yearly_summary = (\n",
    "    subjects\n",
    "        .set_index(\"year\")\n",
    "        .groupby(group_keys)\n",
    "        .apply(lambda g: summarize_subjects_configurable(g, cfg))\n",
    ")\n",
    "\n",
    "yearly_summary = col_to_int(yearly_summary, INT_COLS_OF_SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea39ac",
   "metadata": {},
   "source": [
    "## Project Lifecycle Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = [\"repo_age_group\"]\n",
    "\n",
    "cfg = SummarizeConfig(\n",
    "    include_metrics=ALL_METRICS,\n",
    "    group_keys=tuple(group_keys),\n",
    ")\n",
    "\n",
    "summary_per_repo_age_group = (\n",
    "    subjects\n",
    "        .set_index(\"repo_age_group\")\n",
    "        .groupby(group_keys)\n",
    "        .apply(lambda g: summarize_subjects_configurable(g, cfg))\n",
    ")\n",
    "\n",
    "summary_per_repo_age_group = col_to_int(summary_per_repo_age_group, INT_COLS_OF_SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_per_repo_age_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd8723",
   "metadata": {},
   "source": [
    "## Channel Evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eedb44d",
   "metadata": {},
   "source": [
    "### Function to get value counts for a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2745ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc_detected_channels(\n",
    "    g: pd.DataFrame,\n",
    "    *,\n",
    "    drop_empty: bool = True,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns value_counts of channels for one group g.\n",
    "    Assumes g[\"detected_channels\"] contains iterables/tuples of channels, possibly empty () or NaN.\n",
    "    \"\"\"\n",
    "    col: str = \"detected_channels\"\n",
    "    s = g[col]\n",
    "\n",
    "    # explode expects list-like; NaN stays NaN; () becomes empty -> drops on explode\n",
    "    exploded = s.explode()\n",
    "\n",
    "    # Optional cleanup\n",
    "    exploded = exploded.dropna()\n",
    "    exploded = exploded.astype(\"string\")\n",
    "\n",
    "    if drop_empty:\n",
    "        exploded = exploded[exploded.str.strip() != \"\"]\n",
    "\n",
    "    # value_counts -> counts per channel\n",
    "    vc = exploded.value_counts(dropna=False)\n",
    "\n",
    "    # Make the result stable/consistent\n",
    "    vc.index.name = \"channel\"\n",
    "    vc.name = \"count\"\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373908b",
   "metadata": {},
   "source": [
    "### Channel counts per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79966104",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = [\"year\"]\n",
    "\n",
    "channels_per_year = (\n",
    "    subjects\n",
    "        .groupby(group_keys)[[\"detected_channels\"]]\n",
    "        .apply(vc_detected_channels)\n",
    ")\n",
    "\n",
    "channels_matrix = channels_per_year.unstack(fill_value=0).reset_index()\n",
    "\n",
    "channels_per_year = channels_per_year.reset_index()\n",
    "\n",
    "stats = (\n",
    "    channels_per_year\n",
    "        .groupby(group_keys)[\"count\"]\n",
    "        .apply(value_counts_stats)\n",
    ").unstack(fill_value=0)\n",
    "\n",
    "n = 3\n",
    "\n",
    "top_n_per_year = (\n",
    "    channels_per_year\n",
    "        .sort_values([\"year\", \"count\"], ascending=[True, False])\n",
    "        .groupby(\"year\", dropna=False, sort=False)\n",
    "        .head(n)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "bottom_n_per_year = (\n",
    "    channels_per_year\n",
    "        .sort_values([\"year\", \"count\"], ascending=[True, False])\n",
    "        .groupby(\"year\", dropna=False, sort=False)\n",
    "        .tail(n)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02050f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_n_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f79a9",
   "metadata": {},
   "source": [
    "### Channel counts per repo age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = [\"repo_age_group\"]\n",
    "\n",
    "channels_per_ag = (\n",
    "    subjects\n",
    "        .groupby(group_keys)[[\"detected_channels\"]]\n",
    "        .apply(vc_detected_channels)\n",
    ")\n",
    "\n",
    "channels_matrix_per_ag = channels_per_ag.unstack(fill_value=0).reset_index()\n",
    "channels_matrix_per_ag.set_index(\"repo_age_group\", inplace=True)\n",
    "\n",
    "\n",
    "channels_per_ag = channels_per_ag.reset_index()\n",
    "\n",
    "stats_per_ag = (\n",
    "    channels_per_ag\n",
    "        .groupby(group_keys)[\"count\"]\n",
    "        .apply(value_counts_stats)\n",
    ").unstack(fill_value=0)\n",
    "\n",
    "n = 3\n",
    "\n",
    "top_n_per_ag = (\n",
    "    channels_per_ag\n",
    "        .sort_values([\"repo_age_group\", \"count\"], ascending=[True, False])\n",
    "        .groupby(\"repo_age_group\", dropna=False, sort=False)\n",
    "        .head(n)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "bottom_n_per_ag = (\n",
    "    channels_per_ag\n",
    "        .sort_values([\"repo_age_group\", \"count\"], ascending=[True, False])\n",
    "        .groupby(\"repo_age_group\", dropna=False, sort=False)\n",
    "        .tail(n)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_matrix_per_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_per_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d808884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_per_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_n_per_ag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f4064",
   "metadata": {},
   "source": [
    "### Per repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bacac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = [\"full_name_of_repo\"]\n",
    "\n",
    "channels_per_repo = (\n",
    "    subjects\n",
    "        .groupby(group_keys)[[\"detected_channels\"]]\n",
    "        .apply(vc_detected_channels)\n",
    ")\n",
    "\n",
    "channels_matrix_per_repo = channels_per_repo.unstack(fill_value=0).reset_index()\n",
    "channels_matrix_per_repo.set_index(\"full_name_of_repo\", inplace=True)\n",
    "\n",
    "\n",
    "channels_per_repo = channels_per_repo.reset_index()\n",
    "\n",
    "stats_per_repo = (\n",
    "    channels_per_repo\n",
    "        .groupby(group_keys)[\"count\"]\n",
    "        .apply(value_counts_stats)\n",
    ").unstack(fill_value=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb32a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_per_repo.sort_values(\"n_categories\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autumn-2025-results",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
